{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Job 4: Advanced Analytics and User-Defined Functions (UDFs)\n\n\nLearning Objectives:\n- Creating and using User-Defined Functions (UDFs)\n- Pandas UDFs for better performance\n- Complex analytics patterns (cohort analysis, RFM scoring)\n- Pivot tables and data reshaping\n- Advanced statistical operations\n\nKey Concepts:\n- UDFs allow custom Python logic in Spark\n- Regular UDFs are slow (serialization overhead)\n- Pandas UDFs are much faster (vectorized operations)\n- Use built-in functions when possible"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Setup: Import Libraries and Initialize Spark"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nimport os\nfrom dotenv import load_dotenv\n\n# Load environment variables\nload_dotenv()\n\n# Add project root to path  \nproject_root = os.path.dirname(os.getcwd())\nsys.path.append(project_root)\n\nimport sys\nimport os\n\nprint(\"\u2705 Libraries imported successfully!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Initialize Spark Session\nspark = get_spark_session(\"Job 4: Advanced Analytics and User-Defined Functions (UDFs)\")\ndata_dir = get_data_dir()\n\nprint(f\"\u2705 Spark session created!\")\nprint(f\"\ud83d\udcca Spark UI: http://localhost:4040\")\nprint(f\"\ud83d\udcc1 Data directory: {data_dir}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Generate sample data if it doesn't exist\nfrom utils.data_generator import generate_all_datasets\nimport os\n\ndata_files = os.path.join(data_dir, \"users.csv\")\nif not os.path.exists(data_files):\n    print(\"\ud83d\udcc1 Sample data not found. Generating...\")\n    generate_all_datasets(data_dir)\n    print(\"\u2705 Sample data generated!\")\nelse:\n    print(\"\u2705 Sample data already exists.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## LESSON 1: Regular User-Defined Functions (UDFs)\n\n    \n    UDFs let you apply custom Python functions to DataFrame columns.\n    \n    WARNING: Regular UDFs are slow because:\n    - Data is serialized to Python\n    - Processed row-by-row\n    - Results serialized back to JVM\n    \n    Use built-in functions when possible!"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\" + \"=\"*70)\n    print(\"LESSON 1: Regular UDFs (User-Defined Functions)\")\n    print(\"=\"*70)\n    \n    # Define a simple Python function\n    def categorize_age(age):\n        \"\"\"Categorize age into groups\"\"\"\n        if age is None:\n            return \"Unknown\"\n        elif age < 25:\n            return \"Young Adult\"\n        elif age < 40:\n            return \"Adult\"\n        elif age < 60:\n            return \"Middle Aged\"\n        else:\n            return \"Senior\"\n    \n    # Register as UDF\n    categorize_age_udf = udf(categorize_age, StringType())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\ud83d\udd39 Using UDF to categorize ages:\")\n    result = df.withColumn(\"age_category\", categorize_age_udf(col(\"age\")))\n    result.select(\"name\", \"age\", \"age_category\").show(10)\n    \n    # Alternative: Use SQL-style when() instead (FASTER!)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\ud83d\udd39 Same logic using when() - MUCH FASTER:\")\n    result_optimized = df.withColumn(\n        \"age_category\",\n        when(col(\"age\").isNull(), \"Unknown\")\n        .when(col(\"age\") < 25, \"Young Adult\")\n        .when(col(\"age\") < 40, \"Adult\")\n        .when(col(\"age\") < 60, \"Middle Aged\")\n        .otherwise(\"Senior\")\n    )\n    result_optimized.select(\"name\", \"age\", \"age_category\").show(10)\n    \n    print(\"\\n\ud83d\udca1 Prefer built-in functions over UDFs for better performance!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## LESSON 2: Pandas UDFs (Vectorized UDFs)\n\n    \n    Pandas UDFs process data in batches using Apache Arrow, making them\n    much faster than regular UDFs.\n    \n    Types:\n    - Scalar: Operate on Series, return Series\n    - Grouped Map: Operate on DataFrame, return DataFrame"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\" + \"=\"*70)\n    print(\"LESSON 2: Pandas UDFs (Vectorized - Much Faster!)\")\n    print(\"=\"*70)\n    \n    # Define a Pandas UDF\n    @pandas_udf(StringType())\n    def email_domain(emails: pd.Series) -> pd.Series:\n        \"\"\"Extract domain from email addresses\"\"\"\n        return emails.str.split('@').str[1]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\ud83d\udd39 Using Pandas UDF to extract email domains:\")\n    result = df.withColumn(\"email_domain\", email_domain(col(\"email\")))\n    result.select(\"name\", \"email\", \"email_domain\").show(10)\n    \n    # Another example: Custom scoring\n    @pandas_udf(DoubleType())\n    def custom_age_score(ages: pd.Series) -> pd.Series:\n        \"\"\"Calculate a custom score based on age\"\"\"\n        return ages * 1.5 + 10.0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\ud83d\udd39 Custom scoring with Pandas UDF:\")\n    result = df.withColumn(\"age_score\", custom_age_score(col(\"age\")))\n    result.select(\"name\", \"age\", \"age_score\").show(10)\n    \n    print(\"\\n\ud83d\udca1 Pandas UDFs are 10-100x faster than regular UDFs!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## LESSON 3: Pivot Tables\n\n    \n    Pivot tables reshape data, turning row values into columns.\n    Useful for creating crosstab reports and wide-format data."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\" + \"=\"*70)\n    print(\"LESSON 3: Pivot Tables\")\n    print(\"=\"*70)\n    \n    # Join transactions with products\n    data = transactions_df.filter(col(\"status\") == \"completed\") \\\n        .join(products_df, \"product_id\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\ud83d\udd39 Revenue by category and status:\")\n    pivot_result = data.groupBy(\"category\") \\\n        .pivot(\"status\") \\\n        .agg(spark_sum(\"amount\"))\n    \n    pivot_result.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\ud83d\udd39 Count of transactions by category and month:\")\n    # Extract month from date\n    data_with_month = data.withColumn(\n        \"month\",\n        expr(\"substring(transaction_date, 6, 2)\")\n    )\n    \n    monthly_pivot = data_with_month.groupBy(\"category\") \\\n        .pivot(\"month\") \\\n        .agg(count(\"transaction_id\"))\n    \n    monthly_pivot.show()\n    \n    print(\"\\n\ud83d\udca1 Pivot is great for creating Excel-like reports!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## LESSON 4: RFM Analysis (Recency, Frequency, Monetary)\n\n    \n    RFM is a classic marketing analytics technique:\n    - Recency: How recently did the customer purchase?\n    - Frequency: How often do they purchase?\n    - Monetary: How much do they spend?\n    \n    Used for customer segmentation and targeting."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\" + \"=\"*70)\n    print(\"LESSON 4: RFM Analysis (Customer Segmentation)\")\n    print(\"=\"*70)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\ud83d\udd39 Calculating RFM scores for each customer:\")\n    \n    # Calculate RFM metrics\n    rfm = transactions_df.filter(col(\"status\") == \"completed\") \\\n        .groupBy(\"user_id\") \\\n        .agg(\n            datediff(current_date(), spark_max(\"transaction_date\")).alias(\"recency\"),\n            count(\"transaction_id\").alias(\"frequency\"),\n            spark_sum(\"amount\").alias(\"monetary\")\n        )\n    \n    # Join with user data\n    rfm_with_users = rfm.join(users_df, \"user_id\") \\\n        .select(\"user_id\", \"name\", \"recency\", \"frequency\", \"monetary\")\n    \n    print(\"\\nRaw RFM metrics:\")\n    rfm_with_users.orderBy(desc(\"monetary\")).show(10)\n    \n    # Score each dimension (1-5, where 5 is best)\n    # For recency: lower is better (more recent)\n    # For frequency and monetary: higher is better\n    \n    from pyspark.sql import Window\n    \n    window_spec = Window.orderBy(col(\"recency\"))\n    rfm_scored = rfm_with_users \\\n        .withColumn(\"r_score\", 6 - ntile(5).over(window_spec)) \\\n        .withColumn(\"f_score\", ntile(5).over(Window.orderBy(col(\"frequency\")))) \\\n        .withColumn(\"m_score\", ntile(5).over(Window.orderBy(col(\"monetary\"))))\n    \n    # Calculate overall RFM score\n    rfm_scored = rfm_scored.withColumn(\n        \"rfm_score\",\n        col(\"r_score\") * 100 + col(\"f_score\") * 10 + col(\"m_score\")\n    )"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\ud83d\udd39 RFM Scores (555 is best customer):\")\n    rfm_scored.select(\n        \"name\", \"recency\", \"frequency\", \"monetary\",\n        \"r_score\", \"f_score\", \"m_score\", \"rfm_score\"\n    ).orderBy(desc(\"rfm_score\")).show(15)\n    \n    # Segment customers\n    rfm_segmented = rfm_scored.withColumn(\n        \"segment\",\n        when((col(\"r_score\") >= 4) & (col(\"f_score\") >= 4) & (col(\"m_score\") >= 4), \"Champions\")\n        .when((col(\"r_score\") >= 3) & (col(\"f_score\") >= 3), \"Loyal Customers\")\n        .when((col(\"r_score\") >= 4) & (col(\"f_score\") <= 2), \"Promising\")\n        .when((col(\"r_score\") <= 2) & (col(\"f_score\") >= 3), \"At Risk\")\n        .when((col(\"r_score\") <= 2) & (col(\"f_score\") <= 2), \"Lost\")\n        .otherwise(\"Others\")\n    )"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\ud83d\udd39 Customer Segments:\")\n    rfm_segmented.groupBy(\"segment\") \\\n        .agg(\n            count(\"*\").alias(\"customer_count\"),\n            avg(\"monetary\").alias(\"avg_monetary\")\n        ) \\\n        .orderBy(desc(\"customer_count\")) \\\n        .show()\n    \n    print(\"\\n\ud83d\udca1 RFM helps identify your best customers and those at risk!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## LESSON 5: Cohort Analysis\n\n    \n    Cohort analysis groups customers by a common characteristic (e.g., signup month)\n    and tracks their behavior over time.\n    \n    Useful for understanding customer retention and lifetime value."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\" + \"=\"*70)\n    print(\"LESSON 5: Cohort Analysis\")\n    print(\"=\"*70)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\ud83d\udd39 Analyzing customer behavior by signup cohort:\")\n    \n    # Define cohort as signup month\n    users_with_cohort = users_df.withColumn(\n        \"cohort\",\n        expr(\"substring(signup_date, 1, 7)\")  # YYYY-MM\n    )\n    \n    # Join with transactions\n    cohort_data = users_with_cohort.join(\n        transactions_df.filter(col(\"status\") == \"completed\"),\n        \"user_id\"\n    )\n    \n    # Calculate months since signup\n    cohort_data = cohort_data.withColumn(\n        \"transaction_month\",\n        expr(\"substring(transaction_date, 1, 7)\")\n    )\n    \n    # Aggregate by cohort\n    cohort_summary = cohort_data.groupBy(\"cohort\") \\\n        .agg(\n            countDistinct(\"user_id\").alias(\"cohort_size\"),\n            count(\"transaction_id\").alias(\"total_transactions\"),\n            spark_sum(\"amount\").alias(\"total_revenue\"),\n            avg(\"amount\").alias(\"avg_order_value\")\n        ) \\\n        .orderBy(\"cohort\")\n    \n    print(\"\\nCohort performance:\")\n    cohort_summary.show(20)\n    \n    # Transaction count by cohort and month"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\ud83d\udd39 Transactions by cohort over time:\")\n    cohort_monthly = cohort_data.groupBy(\"cohort\", \"transaction_month\") \\\n        .agg(count(\"transaction_id\").alias(\"transactions\")) \\\n        .orderBy(\"cohort\", \"transaction_month\")\n    \n    cohort_monthly.show(20)\n    \n    print(\"\\n\ud83d\udca1 Cohort analysis reveals how different customer groups behave over time!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## LESSON 6: Statistical Functions\n\n    \n    Spark provides various statistical functions for data analysis."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\" + \"=\"*70)\n    print(\"LESSON 6: Statistical Functions\")\n    print(\"=\"*70)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\ud83d\udd39 Basic statistics:\")\n    df.select(\"age\").describe().show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\ud83d\udd39 Correlation between age and user_id (example):\")\n    correlation = df.stat.corr(\"user_id\", \"age\")\n    print(f\"Correlation: {correlation:.4f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\ud83d\udd39 Percentiles:\")\n    percentiles = df.stat.approxQuantile(\"age\", [0.25, 0.5, 0.75, 0.95], 0.01)\n    print(f\"25th percentile: {percentiles[0]}\")\n    print(f\"50th percentile (median): {percentiles[1]}\")\n    print(f\"75th percentile: {percentiles[2]}\")\n    print(f\"95th percentile: {percentiles[3]}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\ud83d\udd39 Cross-tabulation (country vs age group):\")\n    df_with_age_group = df.withColumn(\n        \"age_group\",\n        when(col(\"age\") < 30, \"<30\")\n        .when(col(\"age\") < 50, \"30-50\")\n        .otherwise(\"50+\")\n    )\n    \n    crosstab = df_with_age_group.stat.crosstab(\"country\", \"age_group\")\n    crosstab.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## LESSON 7: Funnel Analysis\n\n    \n    Analyze user journeys through different stages (view -> click -> cart -> purchase).\n    Critical for conversion optimization."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\" + \"=\"*70)\n    print(\"LESSON 7: Funnel Analysis\")\n    print(\"=\"*70)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\ud83d\udd39 Analyzing the purchase funnel:\")\n    \n    # Count users at each stage\n    funnel = clickstream_df.groupBy(\"event_type\") \\\n        .agg(countDistinct(\"user_id\").alias(\"unique_users\")) \\\n        .orderBy(\"unique_users\", ascending=False)\n    \n    print(\"\\nUsers at each funnel stage:\")\n    funnel.show()\n    \n    # Calculate conversion rates"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\ud83d\udd39 Conversion rates between stages:\")\n    \n    # Get counts for each stage\n    stage_counts = {\n        row['event_type']: row['unique_users'] \n        for row in funnel.collect()\n    }\n    \n    # Calculate conversion rates\n    if 'view' in stage_counts and 'click' in stage_counts:\n        view_to_click = (stage_counts['click'] / stage_counts['view']) * 100\n        print(f\"View \u2192 Click: {view_to_click:.2f}%\")\n    \n    if 'click' in stage_counts and 'add_to_cart' in stage_counts:\n        click_to_cart = (stage_counts['add_to_cart'] / stage_counts['click']) * 100\n        print(f\"Click \u2192 Add to Cart: {click_to_cart:.2f}%\")\n    \n    if 'add_to_cart' in stage_counts and 'purchase' in stage_counts:\n        cart_to_purchase = (stage_counts['purchase'] / stage_counts['add_to_cart']) * 100\n        print(f\"Add to Cart \u2192 Purchase: {cart_to_purchase:.2f}%\")\n    \n    # Product-level funnel"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\ud83d\udd39 Top products by engagement:\")\n    product_funnel = clickstream_df.groupBy(\"product_id\") \\\n        .agg(\n            countDistinct(when(col(\"event_type\") == \"view\", col(\"user_id\"))).alias(\"views\"),\n            countDistinct(when(col(\"event_type\") == \"click\", col(\"user_id\"))).alias(\"clicks\"),\n            countDistinct(when(col(\"event_type\") == \"add_to_cart\", col(\"user_id\"))).alias(\"add_to_cart\"),\n            countDistinct(when(col(\"event_type\") == \"purchase\", col(\"user_id\"))).alias(\"purchases\")\n        ) \\\n        .orderBy(desc(\"views\"))\n    \n    product_funnel.show(10)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\n\u2705 Notebook completed! Check the next notebook to continue learning."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cleanup (Optional)\n\nUncomment and run to stop Spark session:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# stop_spark_session(spark)\n# print(\"\u2705 Spark session stopped.\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}